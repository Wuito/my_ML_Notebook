{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 引用相关包数据"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dropout, Dense, LSTM\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 加载数据并将原始数据归一化处理\n",
    "归一化操作时fit_transform要求输入的数据是二维及以上"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "soc_csv = pd.read_csv('../Data/soc.csv')  # 读\n",
    "\n",
    "training_set = soc_csv['SOC']\n",
    "test_set = training_set[300:6473]\n",
    "training_set, test_set = np.array(training_set), np.array(test_set)\n",
    "\n",
    "# 归一化\n",
    "sc = MinMaxScaler(feature_range=(0, 1))  # 定义归一化：归一化到(0，1)之间\n",
    "training_set_scaled = sc.fit_transform(training_set.reshape(-1, 1))  # 求得训练集的最大值，最小值这些训练集固有的属性，并在训练集上进行归一化\n",
    "test_set = sc.transform(test_set.reshape(-1, 1))  # 利用训练集的属性对测试集进行归一化"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 对原始数据进行分组处理，便于LSTM按照组循环学习数据"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "lstm_Time_expansion_step = 60\n",
    "\n",
    "training_data = training_set_scaled[len(training_set_scaled)- int(len(training_set_scaled)/lstm_Time_expansion_step)\n",
    "                                          *lstm_Time_expansion_step : , :]\n",
    "test_set = test_set[len(test_set)- int(len(test_set)/lstm_Time_expansion_step)\n",
    "                                          *lstm_Time_expansion_step : , :]\n",
    "for i in range(lstm_Time_expansion_step, len(training_data)):\n",
    "    train_ = training_data[i - lstm_Time_expansion_step:i, 0]\n",
    "    x_train.append(train_)\n",
    "    y_train.append(training_data[i, 0])\n",
    "\n",
    "# 对训练集进行打乱\n",
    "np.random.seed(7)\n",
    "np.random.shuffle(x_train)\n",
    "np.random.seed(7)\n",
    "np.random.shuffle(y_train)\n",
    "tf.random.set_seed(7)\n",
    "# 将训练集由list格式变为array格式\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], lstm_Time_expansion_step, 1))\n",
    "\n",
    "# 设置测试数据格式\n",
    "for i in range(lstm_Time_expansion_step, len(test_set)):\n",
    "    x_test.append(test_set[i - lstm_Time_expansion_step:i, 0])\n",
    "    y_test.append(test_set[i, 0])\n",
    "x_test, y_test = np.array(x_test), np.array(y_test)\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], lstm_Time_expansion_step, 1))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 构建模型"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    LSTM(80, return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(100),\n",
    "    Dropout(0.2),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              loss='mean_squared_error')  # 损失函数用均方误差\n",
    "# 该应用只观测loss数值，不观测准确率，所以删去metrics选项，一会在每个epoch迭代显示时只显示loss值\n",
    "checkpoint_save_path = \"./checkpoint/soc/LSTM_stock.ckpt\"   # 保存模型\n",
    "tf_model_save_path = \"./checkpoint/soc/socTFmodel\"   # 保存静态模型\n",
    "log_save_path = \"./log/soc/lstm\"\n",
    "os.makedirs(log_save_path, exist_ok=True)\n",
    "\n",
    "if os.path.exists(checkpoint_save_path + '.index'):\n",
    "    print('-------------load the model-----------------')\n",
    "    model.load_weights(checkpoint_save_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_save_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 save_best_only=True,\n",
    "                                                 monitor='val_loss')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 训练"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=64, epochs=30, validation_data=(x_test, y_test), validation_freq=1,\n",
    "                    callbacks=[cp_callback])\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 保存模型权重"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save(tf_model_save_path, save_format='tf')    # 保存模型为静态权重\n",
    "\n",
    "file = open(log_save_path+'/weights.txt', 'w')  # 参数提取\n",
    "for v in model.trainable_variables:\n",
    "    file.write(str(v.name) + '\\n')\n",
    "    file.write(str(v.shape) + '\\n')\n",
    "    file.write(str(v.numpy()) + '\\n')\n",
    "file.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 绘制损失数据曲线"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.savefig(log_save_path+\"/loss.png\", dpi=60)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 预测推理"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 测试集输入模型进行预测\n",
    "predicted_stock_price = model.predict(x_test)\n",
    "# 对预测数据还原---从（0，1）反归一化到原始范围\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price)\n",
    "# 对真实数据还原---从（0，1）反归一化到原始范围\n",
    "real_stock_price = sc.inverse_transform(test_set[60:])\n",
    "# 画出真实数据和预测数据的对比曲线\n",
    "plt.plot(real_stock_price, color='red', label='MaoTai Stock Price')\n",
    "plt.plot(predicted_stock_price, color='blue', label='Predicted MaoTai Stock Price')\n",
    "plt.title('MaoTai Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('MaoTai Stock Price')\n",
    "plt.legend()\n",
    "plt.savefig(log_save_path+\"/predict.png\", dpi=120)\n",
    "plt.show()\n",
    "\n",
    "# calculate MSE 均方误差 ---> E[(预测值-真实值)^2] (预测值减真实值求平方后求均值)\n",
    "mse = mean_squared_error(predicted_stock_price, real_stock_price)\n",
    "# calculate RMSE 均方根误差--->sqrt[MSE]    (对均方误差开方)\n",
    "rmse = math.sqrt(mean_squared_error(predicted_stock_price, real_stock_price))\n",
    "# calculate MAE 平均绝对误差----->E[|预测值-真实值|](预测值减真实值求绝对值后求均值）\n",
    "mae = mean_absolute_error(predicted_stock_price, real_stock_price)\n",
    "print('均方误差: %.6f' % mse)\n",
    "print('均方根误差: %.6f' % rmse)\n",
    "print('平均绝对误差: %.6f' % mae)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
